{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code I wrote when I tried to setup stanford NLP and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 28.9MB/s]                    \n",
      "2021-03-10 14:23:57 INFO: Downloading default packages for language: en (English)...\n",
      "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/en/default.zip: 100%|██████████| 411M/411M [01:15<00:00, 5.41MB/s] \n",
      "2021-03-10 14:25:17 INFO: Finished downloading models and saved to /Users/feiyid/stanza_resources.\n",
      "2021-03-10 14:25:17 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-03-10 14:25:17 INFO: Use device: cpu\n",
      "2021-03-10 14:25:17 INFO: Loading: tokenize\n",
      "2021-03-10 14:25:17 INFO: Loading: pos\n",
      "2021-03-10 14:25:18 INFO: Loading: lemma\n",
      "2021-03-10 14:25:18 INFO: Loading: depparse\n",
      "2021-03-10 14:25:18 INFO: Loading: sentiment\n",
      "2021-03-10 14:25:18 INFO: Loading: ner\n",
      "2021-03-10 14:25:19 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')\n",
    "stanza_nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-10 14:35:44 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "========================\n",
      "\n",
      "2021-03-10 14:35:44 INFO: Use device: cpu\n",
      "2021-03-10 14:35:44 INFO: Loading: tokenize\n",
      "2021-03-10 14:35:44 INFO: Loading: pos\n",
      "2021-03-10 14:35:44 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"Barack\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"misc\": \"start_char=0|end_char=6\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"Obama\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"misc\": \"start_char=7|end_char=12\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"was\",\n",
      "      \"upos\": \"AUX\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"misc\": \"start_char=13|end_char=16\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"born\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBN\",\n",
      "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
      "      \"misc\": \"start_char=17|end_char=21\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"in\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"misc\": \"start_char=22|end_char=24\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"Hawaii\",\n",
      "      \"upos\": \"PROPN\",\n",
      "      \"xpos\": \"NNP\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"misc\": \"start_char=25|end_char=31\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"misc\": \"start_char=31|end_char=32\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline('en', processors='tokenize,pos', use_gpu=True, pos_batch_size=3000) # Build the pipeline, specify part-of-speech processor's batch size\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.\") # Run the pipeline on the input text\n",
    "print(doc) # Look at the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-10 14:35:44 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-03-10 14:35:44 INFO: Use device: cpu\n",
      "2021-03-10 14:35:44 INFO: Loading: tokenize\n",
      "2021-03-10 14:35:44 INFO: Loading: ner\n",
      "2021-03-10 14:35:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Chris Manning\ttype: PERSON\n",
      "entity: Stanford University\ttype: ORG\n",
      "entity: the Bay Area\ttype: LOC\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "doc = nlp(\"Chris Manning teaches at Stanford University. He lives in the Bay Area.\")\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-10 14:35:45 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2021-03-10 14:35:45 INFO: Use device: cpu\n",
      "2021-03-10 14:35:45 INFO: Loading: tokenize\n",
      "2021-03-10 14:35:45 INFO: Loading: sentiment\n",
      "2021-03-10 14:35:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "doc = nlp('I hate that they banned Mox Opal. I love orange vanilla coke.')\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(i, sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
